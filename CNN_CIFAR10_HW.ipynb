{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_CIFAR10_HW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1cd1c17383fa4c08b6a05f1cb27fca0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_393ebdaec96547af95fe24cfd22f307d",
              "IPY_MODEL_0a572f152958447b8b44efd88edd175d",
              "IPY_MODEL_4e958ff7af0548cea43453c273d3a466"
            ],
            "layout": "IPY_MODEL_4d49e58f5a4b409a96c89d67b3be0477"
          }
        },
        "393ebdaec96547af95fe24cfd22f307d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_209d3341b4204e95af60df59295954b9",
            "placeholder": "​",
            "style": "IPY_MODEL_4a111995b8ce423e9ec1895699c81799",
            "value": ""
          }
        },
        "0a572f152958447b8b44efd88edd175d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_281401a9b9f348d9a827caf44165c913",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9542a869085d484885feed8e9ab024a1",
            "value": 170498071
          }
        },
        "4e958ff7af0548cea43453c273d3a466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_849775ff19d044dabe77a680c336b15d",
            "placeholder": "​",
            "style": "IPY_MODEL_9db53f25ed0b4d16a103ea827225a9d7",
            "value": " 170499072/? [00:03&lt;00:00, 51560475.71it/s]"
          }
        },
        "4d49e58f5a4b409a96c89d67b3be0477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "209d3341b4204e95af60df59295954b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a111995b8ce423e9ec1895699c81799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "281401a9b9f348d9a827caf44165c913": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9542a869085d484885feed8e9ab024a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "849775ff19d044dabe77a680c336b15d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db53f25ed0b4d16a103ea827225a9d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shj-A/2022_ML_Project/blob/main/CNN_CIFAR10_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk9qpcpL5ZPS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# you have to set mini-batch size as a hyperparameter\n",
        "# batch size : how many samples per batch to load\n",
        "batch_size = 32\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(\n",
        "    root = './data/CIFAR10',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transform\n",
        ")\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(\n",
        "    root = './data/CIFAR10',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transform\n",
        ")\n",
        "\n",
        "train_data, valid_data = train_test_split(train_data, test_size=0.2, shuffle=True)\n",
        "print('# of train data : {}'.format(len(train_data)))\n",
        "print('# of valid data : {}'.format(len(valid_data)))\n",
        "print('# of test data : {}'.format(len(test_data)))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size = batch_size, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "1cd1c17383fa4c08b6a05f1cb27fca0e",
            "393ebdaec96547af95fe24cfd22f307d",
            "0a572f152958447b8b44efd88edd175d",
            "4e958ff7af0548cea43453c273d3a466",
            "4d49e58f5a4b409a96c89d67b3be0477",
            "209d3341b4204e95af60df59295954b9",
            "4a111995b8ce423e9ec1895699c81799",
            "281401a9b9f348d9a827caf44165c913",
            "9542a869085d484885feed8e9ab024a1",
            "849775ff19d044dabe77a680c336b15d",
            "9db53f25ed0b4d16a103ea827225a9d7"
          ]
        },
        "id": "h2ugdpqWjqI6",
        "outputId": "1669476c-4c86-4183-b9f3-cd1912609e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/CIFAR10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cd1c17383fa4c08b6a05f1cb27fca0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/CIFAR10/cifar-10-python.tar.gz to ./data/CIFAR10\n",
            "Files already downloaded and verified\n",
            "# of train data : 40000\n",
            "# of valid data : 10000\n",
            "# of test data : 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = enumerate(train_data)\n",
        "batch_index, (example_data, example_label) = next(examples)\n",
        "print(example_data.shape)\n",
        "print('input image channel : {}'.format(example_data.shape[0]))\n",
        "print('input image size : {} * {}'.format(example_data.shape[1], example_data.shape[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qiWWvLd5dIU",
        "outputId": "bc58555b-3891-409d-f3f4-e1620f837de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "input image channel : 3\n",
            "input image size : 32 * 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-1 change the current kernel size"
      ],
      "metadata": {
        "id": "MeqQ9lrldU0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "n_epochs = 5\n",
        "learning_rate = 0.01\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "5mwKcXX3v-4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size = batch_size, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "DQh0puQfwDYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding='same')\n",
        "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding= 'same')\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 8 * 8 * 16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "OVNfjkrNOYB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    model = CNN()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UqGwC-COzRy",
        "outputId": "42237806-1134-4055-8f20-b4bbcc3ea72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.749\t training accuracy : 0.354\n",
            "validation loss : 1.583\t validation accuracy : 0.414\n",
            "validation accuracy improved 0.00000 ======> 0.41400\n",
            "[2/5]\n",
            "training loss : 1.583\t training accuracy : 0.422\n",
            "validation loss : 1.572\t validation accuracy : 0.424\n",
            "validation accuracy improved 0.41400 ======> 0.42410\n",
            "[3/5]\n",
            "training loss : 1.537\t training accuracy : 0.441\n",
            "validation loss : 1.606\t validation accuracy : 0.417\n",
            "[4/5]\n",
            "training loss : 1.512\t training accuracy : 0.449\n",
            "validation loss : 1.493\t validation accuracy : 0.466\n",
            "validation accuracy improved 0.42410 ======> 0.46610\n",
            "[5/5]\n",
            "training loss : 1.487\t training accuracy : 0.463\n",
            "validation loss : 1.591\t validation accuracy : 0.437\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.806\t training accuracy : 0.326\n",
            "validation loss : 1.742\t validation accuracy : 0.357\n",
            "validation accuracy improved 0.00000 ======> 0.35690\n",
            "[2/5]\n",
            "training loss : 1.629\t training accuracy : 0.401\n",
            "validation loss : 1.630\t validation accuracy : 0.406\n",
            "validation accuracy improved 0.35690 ======> 0.40560\n",
            "[3/5]\n",
            "training loss : 1.591\t training accuracy : 0.418\n",
            "validation loss : 1.608\t validation accuracy : 0.412\n",
            "validation accuracy improved 0.40560 ======> 0.41180\n",
            "[4/5]\n",
            "training loss : 1.571\t training accuracy : 0.428\n",
            "validation loss : 1.622\t validation accuracy : 0.423\n",
            "validation accuracy improved 0.41180 ======> 0.42290\n",
            "[5/5]\n",
            "training loss : 1.564\t training accuracy : 0.432\n",
            "validation loss : 1.610\t validation accuracy : 0.429\n",
            "validation accuracy improved 0.42290 ======> 0.42900\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.721\t training accuracy : 0.360\n",
            "validation loss : 1.562\t validation accuracy : 0.431\n",
            "validation accuracy improved 0.00000 ======> 0.43110\n",
            "[2/5]\n",
            "training loss : 1.553\t training accuracy : 0.439\n",
            "validation loss : 1.541\t validation accuracy : 0.435\n",
            "validation accuracy improved 0.43110 ======> 0.43550\n",
            "[3/5]\n",
            "training loss : 1.500\t training accuracy : 0.460\n",
            "validation loss : 1.536\t validation accuracy : 0.450\n",
            "validation accuracy improved 0.43550 ======> 0.45040\n",
            "[4/5]\n",
            "training loss : 1.462\t training accuracy : 0.477\n",
            "validation loss : 1.473\t validation accuracy : 0.482\n",
            "validation accuracy improved 0.45040 ======> 0.48170\n",
            "[5/5]\n",
            "training loss : 1.431\t training accuracy : 0.489\n",
            "validation loss : 1.529\t validation accuracy : 0.462\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kernelsize = 5\n",
        "class CNN_1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 5, padding = 'same')\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 5, padding = 'same')\n",
        "        self.fc1 = nn.Linear(16 * 8 * 8, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    "
      ],
      "metadata": {
        "id": "Gq_JInI95eSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    model = CNN_1()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "IGjkE9rrl8ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56225b15-4f59-4b91-e267-d741df6fd828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_1(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.996\t training accuracy : 0.244\n",
            "validation loss : 1.899\t validation accuracy : 0.285\n",
            "validation accuracy improved 0.00000 ======> 0.28530\n",
            "[2/5]\n",
            "training loss : 1.869\t training accuracy : 0.281\n",
            "validation loss : 1.922\t validation accuracy : 0.271\n",
            "[3/5]\n",
            "training loss : 1.827\t training accuracy : 0.296\n",
            "validation loss : 2.009\t validation accuracy : 0.260\n",
            "[4/5]\n",
            "training loss : 1.787\t training accuracy : 0.310\n",
            "validation loss : 1.765\t validation accuracy : 0.316\n",
            "validation accuracy improved 0.28530 ======> 0.31600\n",
            "[5/5]\n",
            "training loss : 1.765\t training accuracy : 0.315\n",
            "validation loss : 1.746\t validation accuracy : 0.309\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_1(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.304\t training accuracy : 0.100\n",
            "validation loss : 2.303\t validation accuracy : 0.104\n",
            "validation accuracy improved 0.00000 ======> 0.10420\n",
            "[2/5]\n",
            "training loss : 2.304\t training accuracy : 0.101\n",
            "validation loss : 2.303\t validation accuracy : 0.106\n",
            "validation accuracy improved 0.10420 ======> 0.10580\n",
            "[3/5]\n",
            "training loss : 2.304\t training accuracy : 0.099\n",
            "validation loss : 2.303\t validation accuracy : 0.101\n",
            "[4/5]\n",
            "training loss : 2.304\t training accuracy : 0.101\n",
            "validation loss : 2.303\t validation accuracy : 0.100\n",
            "[5/5]\n",
            "training loss : 2.304\t training accuracy : 0.102\n",
            "validation loss : 2.303\t validation accuracy : 0.100\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_1(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.305\t training accuracy : 0.097\n",
            "validation loss : 2.303\t validation accuracy : 0.100\n",
            "validation accuracy improved 0.00000 ======> 0.10010\n",
            "[2/5]\n",
            "training loss : 2.304\t training accuracy : 0.100\n",
            "validation loss : 2.303\t validation accuracy : 0.100\n",
            "[3/5]\n",
            "training loss : 2.304\t training accuracy : 0.098\n",
            "validation loss : 2.303\t validation accuracy : 0.101\n",
            "validation accuracy improved 0.10010 ======> 0.10130\n",
            "[4/5]\n",
            "training loss : 2.304\t training accuracy : 0.098\n",
            "validation loss : 2.303\t validation accuracy : 0.100\n",
            "[5/5]\n",
            "training loss : 2.304\t training accuracy : 0.098\n",
            "validation loss : 2.303\t validation accuracy : 0.102\n",
            "validation accuracy improved 0.10130 ======> 0.10220\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kernelsize = 7\n",
        "class CNN_2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 5, padding = 'same')\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 5, padding = 'same')\n",
        "        self.fc1 = nn.Linear(16 * 8 * 8, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qDVeii3Xd3eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    model = CNN_2()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjJxnL_Gd-jO",
        "outputId": "4f9c3301-519b-43de-bebc-dc6e843a793c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_2(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.055\t training accuracy : 0.232\n",
            "validation loss : 2.011\t validation accuracy : 0.259\n",
            "validation accuracy improved 0.00000 ======> 0.25870\n",
            "[2/5]\n",
            "training loss : 1.935\t training accuracy : 0.277\n",
            "validation loss : 1.859\t validation accuracy : 0.308\n",
            "validation accuracy improved 0.25870 ======> 0.30770\n",
            "[3/5]\n",
            "training loss : 1.839\t training accuracy : 0.312\n",
            "validation loss : 1.789\t validation accuracy : 0.336\n",
            "validation accuracy improved 0.30770 ======> 0.33640\n",
            "[4/5]\n",
            "training loss : 1.788\t training accuracy : 0.331\n",
            "validation loss : 1.811\t validation accuracy : 0.307\n",
            "[5/5]\n",
            "training loss : 1.756\t training accuracy : 0.339\n",
            "validation loss : 1.719\t validation accuracy : 0.351\n",
            "validation accuracy improved 0.33640 ======> 0.35100\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_2(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.000\t training accuracy : 0.250\n",
            "validation loss : 1.898\t validation accuracy : 0.278\n",
            "validation accuracy improved 0.00000 ======> 0.27800\n",
            "[2/5]\n",
            "training loss : 1.867\t training accuracy : 0.295\n",
            "validation loss : 1.807\t validation accuracy : 0.328\n",
            "validation accuracy improved 0.27800 ======> 0.32790\n",
            "[3/5]\n",
            "training loss : 1.798\t training accuracy : 0.313\n",
            "validation loss : 1.751\t validation accuracy : 0.337\n",
            "validation accuracy improved 0.32790 ======> 0.33730\n",
            "[4/5]\n",
            "training loss : 1.770\t training accuracy : 0.324\n",
            "validation loss : 1.817\t validation accuracy : 0.318\n",
            "[5/5]\n",
            "training loss : 1.758\t training accuracy : 0.328\n",
            "validation loss : 1.732\t validation accuracy : 0.339\n",
            "validation accuracy improved 0.33730 ======> 0.33920\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_2(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.950\t training accuracy : 0.267\n",
            "validation loss : 1.815\t validation accuracy : 0.310\n",
            "validation accuracy improved 0.00000 ======> 0.31030\n",
            "[2/5]\n",
            "training loss : 1.816\t training accuracy : 0.323\n",
            "validation loss : 1.816\t validation accuracy : 0.332\n",
            "validation accuracy improved 0.31030 ======> 0.33220\n",
            "[3/5]\n",
            "training loss : 1.779\t training accuracy : 0.332\n",
            "validation loss : 1.737\t validation accuracy : 0.350\n",
            "validation accuracy improved 0.33220 ======> 0.35030\n",
            "[4/5]\n",
            "training loss : 1.748\t training accuracy : 0.348\n",
            "validation loss : 1.777\t validation accuracy : 0.351\n",
            "validation accuracy improved 0.35030 ======> 0.35100\n",
            "[5/5]\n",
            "training loss : 1.729\t training accuracy : 0.354\n",
            "validation loss : 1.708\t validation accuracy : 0.368\n",
            "validation accuracy improved 0.35100 ======> 0.36830\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-2 different pooling layer "
      ],
      "metadata": {
        "id": "UJNMA1uX-xbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding='same')\n",
        "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding= 'same')\n",
        "        self.fc1 = nn.Linear(32 * 32 * 16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(-1, 32 * 32 * 16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "-5E002sT_Mr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    model = CNN_3()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmCwcBqJf2po",
        "outputId": "9c2cd948-1428-4cd8-d198-2bdebd6f5067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_3(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.310\t training accuracy : 0.100\n",
            "validation loss : 2.304\t validation accuracy : 0.100\n",
            "validation accuracy improved 0.00000 ======> 0.09960\n",
            "[2/5]\n",
            "training loss : 2.304\t training accuracy : 0.100\n",
            "validation loss : 2.304\t validation accuracy : 0.095\n",
            "[3/5]\n",
            "training loss : 2.304\t training accuracy : 0.101\n",
            "validation loss : 2.304\t validation accuracy : 0.101\n",
            "validation accuracy improved 0.09960 ======> 0.10130\n",
            "[4/5]\n",
            "training loss : 2.304\t training accuracy : 0.101\n",
            "validation loss : 2.304\t validation accuracy : 0.097\n",
            "[5/5]\n",
            "training loss : 2.304\t training accuracy : 0.098\n",
            "validation loss : 2.304\t validation accuracy : 0.095\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_3(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.926\t training accuracy : 0.287\n",
            "validation loss : 1.748\t validation accuracy : 0.361\n",
            "validation accuracy improved 0.00000 ======> 0.36090\n",
            "[2/5]\n",
            "training loss : 1.694\t training accuracy : 0.384\n",
            "validation loss : 1.744\t validation accuracy : 0.364\n",
            "validation accuracy improved 0.36090 ======> 0.36410\n",
            "[3/5]\n",
            "training loss : 1.595\t training accuracy : 0.421\n",
            "validation loss : 1.682\t validation accuracy : 0.403\n",
            "validation accuracy improved 0.36410 ======> 0.40300\n",
            "[4/5]\n",
            "training loss : 1.494\t training accuracy : 0.460\n",
            "validation loss : 1.689\t validation accuracy : 0.401\n",
            "[5/5]\n",
            "training loss : 1.432\t training accuracy : 0.488\n",
            "validation loss : 1.725\t validation accuracy : 0.407\n",
            "validation accuracy improved 0.40300 ======> 0.40750\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_3(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (fc1): Linear(in_features=16384, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.900\t training accuracy : 0.291\n",
            "validation loss : 1.808\t validation accuracy : 0.321\n",
            "validation accuracy improved 0.00000 ======> 0.32070\n",
            "[2/5]\n",
            "training loss : 1.761\t training accuracy : 0.346\n",
            "validation loss : 1.729\t validation accuracy : 0.366\n",
            "validation accuracy improved 0.32070 ======> 0.36600\n",
            "[3/5]\n",
            "training loss : 1.735\t training accuracy : 0.350\n",
            "validation loss : 1.725\t validation accuracy : 0.366\n",
            "validation accuracy improved 0.36600 ======> 0.36610\n",
            "[4/5]\n",
            "training loss : 1.676\t training accuracy : 0.379\n",
            "validation loss : 1.735\t validation accuracy : 0.358\n",
            "[5/5]\n",
            "training loss : 1.649\t training accuracy : 0.397\n",
            "validation loss : 1.714\t validation accuracy : 0.381\n",
            "validation accuracy improved 0.36610 ======> 0.38060\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-3 Avg pooling"
      ],
      "metadata": {
        "id": "LgKrKrm1oZdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_4, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding='same')\n",
        "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding= 'same')\n",
        "        self.pool = nn.AvgPool2d(kernel_size = 2, stride = 2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 8 * 8 * 16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "nrP7SWKkoncO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    model = CNN_4()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0Rvzdlyk3Yt",
        "outputId": "7b45279b-64bd-4901-f324-301800b30f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_4(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.730\t training accuracy : 0.357\n",
            "validation loss : 1.566\t validation accuracy : 0.427\n",
            "validation accuracy improved 0.00000 ======> 0.42690\n",
            "[2/5]\n",
            "training loss : 1.527\t training accuracy : 0.450\n",
            "validation loss : 1.493\t validation accuracy : 0.456\n",
            "validation accuracy improved 0.42690 ======> 0.45630\n",
            "[3/5]\n",
            "training loss : 1.433\t training accuracy : 0.485\n",
            "validation loss : 1.453\t validation accuracy : 0.482\n",
            "validation accuracy improved 0.45630 ======> 0.48190\n",
            "[4/5]\n",
            "training loss : 1.361\t training accuracy : 0.519\n",
            "validation loss : 1.411\t validation accuracy : 0.503\n",
            "validation accuracy improved 0.48190 ======> 0.50300\n",
            "[5/5]\n",
            "training loss : 1.318\t training accuracy : 0.534\n",
            "validation loss : 1.375\t validation accuracy : 0.520\n",
            "validation accuracy improved 0.50300 ======> 0.52040\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_4(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.630\t training accuracy : 0.397\n",
            "validation loss : 1.471\t validation accuracy : 0.467\n",
            "validation accuracy improved 0.00000 ======> 0.46700\n",
            "[2/5]\n",
            "training loss : 1.412\t training accuracy : 0.493\n",
            "validation loss : 1.405\t validation accuracy : 0.502\n",
            "validation accuracy improved 0.46700 ======> 0.50170\n",
            "[3/5]\n",
            "training loss : 1.323\t training accuracy : 0.530\n",
            "validation loss : 1.341\t validation accuracy : 0.530\n",
            "validation accuracy improved 0.50170 ======> 0.53050\n",
            "[4/5]\n",
            "training loss : 1.282\t training accuracy : 0.548\n",
            "validation loss : 1.330\t validation accuracy : 0.534\n",
            "validation accuracy improved 0.53050 ======> 0.53370\n",
            "[5/5]\n",
            "training loss : 1.231\t training accuracy : 0.570\n",
            "validation loss : 1.310\t validation accuracy : 0.550\n",
            "validation accuracy improved 0.53370 ======> 0.55040\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_4(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.637\t training accuracy : 0.400\n",
            "validation loss : 1.491\t validation accuracy : 0.449\n",
            "validation accuracy improved 0.00000 ======> 0.44930\n",
            "[2/5]\n",
            "training loss : 1.412\t training accuracy : 0.488\n",
            "validation loss : 1.382\t validation accuracy : 0.507\n",
            "validation accuracy improved 0.44930 ======> 0.50670\n",
            "[3/5]\n",
            "training loss : 1.326\t training accuracy : 0.525\n",
            "validation loss : 1.388\t validation accuracy : 0.512\n",
            "validation accuracy improved 0.50670 ======> 0.51180\n",
            "[4/5]\n",
            "training loss : 1.268\t training accuracy : 0.550\n",
            "validation loss : 1.268\t validation accuracy : 0.561\n",
            "validation accuracy improved 0.51180 ======> 0.56110\n",
            "[5/5]\n",
            "training loss : 1.225\t training accuracy : 0.568\n",
            "validation loss : 1.365\t validation accuracy : 0.538\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-4 Change activation function"
      ],
      "metadata": {
        "id": "AYMFp1Co7_WJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid"
      ],
      "metadata": {
        "id": "19H6qbgUD2Re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding='same')\n",
        "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding= 'same')\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.sigmoid(self.conv1(x)))\n",
        "        x = self.pool(F.sigmoid(self.conv2(x)))\n",
        "        x = x.view(-1, 8 * 8 * 16)\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        x = F.sigmoid(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "AvStEuMi8RIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    model = CNN_5()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pzz4cO4lvow",
        "outputId": "b36c8443-e8e4-48eb-b362-2ca1faed3e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_5(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/5]\n",
            "training loss : 2.305\t training accuracy : 0.100\n",
            "validation loss : 2.304\t validation accuracy : 0.097\n",
            "validation accuracy improved 0.00000 ======> 0.09710\n",
            "[2/5]\n",
            "training loss : 2.304\t training accuracy : 0.096\n",
            "validation loss : 2.305\t validation accuracy : 0.102\n",
            "validation accuracy improved 0.09710 ======> 0.10220\n",
            "[3/5]\n",
            "training loss : 2.304\t training accuracy : 0.098\n",
            "validation loss : 2.305\t validation accuracy : 0.096\n",
            "[4/5]\n",
            "training loss : 2.304\t training accuracy : 0.098\n",
            "validation loss : 2.304\t validation accuracy : 0.102\n",
            "[5/5]\n",
            "training loss : 2.304\t training accuracy : 0.099\n",
            "validation loss : 2.304\t validation accuracy : 0.101\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_5(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.305\t training accuracy : 0.101\n",
            "validation loss : 2.305\t validation accuracy : 0.102\n",
            "validation accuracy improved 0.00000 ======> 0.10220\n",
            "[2/5]\n",
            "training loss : 2.304\t training accuracy : 0.099\n",
            "validation loss : 2.304\t validation accuracy : 0.095\n",
            "[3/5]\n",
            "training loss : 2.304\t training accuracy : 0.098\n",
            "validation loss : 2.304\t validation accuracy : 0.099\n",
            "[4/5]\n",
            "training loss : 2.304\t training accuracy : 0.100\n",
            "validation loss : 2.303\t validation accuracy : 0.096\n",
            "[5/5]\n",
            "training loss : 2.304\t training accuracy : 0.098\n",
            "validation loss : 2.306\t validation accuracy : 0.095\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_5(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.305\t training accuracy : 0.097\n",
            "validation loss : 2.304\t validation accuracy : 0.095\n",
            "validation accuracy improved 0.00000 ======> 0.09500\n",
            "[2/5]\n",
            "training loss : 2.304\t training accuracy : 0.099\n",
            "validation loss : 2.304\t validation accuracy : 0.102\n",
            "validation accuracy improved 0.09500 ======> 0.10220\n",
            "[3/5]\n",
            "training loss : 2.304\t training accuracy : 0.097\n",
            "validation loss : 2.303\t validation accuracy : 0.099\n",
            "[4/5]\n",
            "training loss : 2.304\t training accuracy : 0.099\n",
            "validation loss : 2.304\t validation accuracy : 0.102\n",
            "[5/5]\n",
            "training loss : 2.304\t training accuracy : 0.099\n",
            "validation loss : 2.304\t validation accuracy : 0.095\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tanh"
      ],
      "metadata": {
        "id": "9cyCSCn_D538"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_6(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_6, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding='same')\n",
        "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding= 'same')\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.tanh(self.conv1(x)))\n",
        "        x = self.pool(F.tanh(self.conv2(x)))\n",
        "        x = x.view(-1, 8 * 8 * 16)\n",
        "        x = F.tanh(self.fc1(x))\n",
        "        x = F.tanh(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "0fPl7TmyD8Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    model = CNN_6()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVTThLwKEJy7",
        "outputId": "88e37f11-3724-40e0-c945-c432ab587e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_6(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/5]\n",
            "training loss : 1.813\t training accuracy : 0.340\n",
            "validation loss : 1.771\t validation accuracy : 0.354\n",
            "validation accuracy improved 0.00000 ======> 0.35450\n",
            "[2/5]\n",
            "training loss : 1.774\t training accuracy : 0.356\n",
            "validation loss : 1.822\t validation accuracy : 0.334\n",
            "[3/5]\n",
            "training loss : 1.762\t training accuracy : 0.364\n",
            "validation loss : 1.712\t validation accuracy : 0.383\n",
            "validation accuracy improved 0.35450 ======> 0.38300\n",
            "[4/5]\n",
            "training loss : 1.727\t training accuracy : 0.377\n",
            "validation loss : 1.738\t validation accuracy : 0.389\n",
            "validation accuracy improved 0.38300 ======> 0.38900\n",
            "[5/5]\n",
            "training loss : 1.743\t training accuracy : 0.368\n",
            "validation loss : 1.724\t validation accuracy : 0.384\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_6(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.848\t training accuracy : 0.326\n",
            "validation loss : 1.845\t validation accuracy : 0.332\n",
            "validation accuracy improved 0.00000 ======> 0.33150\n",
            "[2/5]\n",
            "training loss : 1.817\t training accuracy : 0.340\n",
            "validation loss : 1.834\t validation accuracy : 0.336\n",
            "validation accuracy improved 0.33150 ======> 0.33550\n",
            "[3/5]\n",
            "training loss : 1.791\t training accuracy : 0.351\n",
            "validation loss : 1.790\t validation accuracy : 0.367\n",
            "validation accuracy improved 0.33550 ======> 0.36730\n",
            "[4/5]\n",
            "training loss : 1.772\t training accuracy : 0.361\n",
            "validation loss : 1.782\t validation accuracy : 0.359\n",
            "[5/5]\n",
            "training loss : 1.787\t training accuracy : 0.350\n",
            "validation loss : 1.846\t validation accuracy : 0.319\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_6(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.817\t training accuracy : 0.340\n",
            "validation loss : 1.708\t validation accuracy : 0.379\n",
            "validation accuracy improved 0.00000 ======> 0.37920\n",
            "[2/5]\n",
            "training loss : 1.741\t training accuracy : 0.369\n",
            "validation loss : 1.688\t validation accuracy : 0.390\n",
            "validation accuracy improved 0.37920 ======> 0.38970\n",
            "[3/5]\n",
            "training loss : 1.736\t training accuracy : 0.373\n",
            "validation loss : 1.705\t validation accuracy : 0.395\n",
            "validation accuracy improved 0.38970 ======> 0.39460\n",
            "[4/5]\n",
            "training loss : 1.711\t training accuracy : 0.382\n",
            "validation loss : 1.708\t validation accuracy : 0.379\n",
            "[5/5]\n",
            "training loss : 1.720\t training accuracy : 0.374\n",
            "validation loss : 1.840\t validation accuracy : 0.343\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-5 dropout 사용"
      ],
      "metadata": {
        "id": "2i30EfkXI_ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_7(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_7, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding='same')\n",
        "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding= 'same')\n",
        "        self.drop = nn.Dropout2d(p=0.25)\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.drop(self.pool(F.relu(self.conv1(x))))\n",
        "        x = self.drop(self.pool(F.relu(self.conv2(x))))\n",
        "        x = x.view(-1, 8 * 8 * 16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "pfSn5NgoJEi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    model = CNN_7()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2I5whSVmxq-",
        "outputId": "a2eae602-1875-41b4-fce5-dabbde4db495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_7(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (drop): Dropout2d(p=0.25, inplace=False)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.979\t training accuracy : 0.255\n",
            "validation loss : 1.839\t validation accuracy : 0.325\n",
            "validation accuracy improved 0.00000 ======> 0.32490\n",
            "[2/5]\n",
            "training loss : 1.882\t training accuracy : 0.300\n",
            "validation loss : 1.802\t validation accuracy : 0.332\n",
            "validation accuracy improved 0.32490 ======> 0.33180\n",
            "[3/5]\n",
            "training loss : 1.846\t training accuracy : 0.314\n",
            "validation loss : 1.812\t validation accuracy : 0.330\n",
            "[4/5]\n",
            "training loss : 1.829\t training accuracy : 0.319\n",
            "validation loss : 1.722\t validation accuracy : 0.361\n",
            "validation accuracy improved 0.33180 ======> 0.36070\n",
            "[5/5]\n",
            "training loss : 1.823\t training accuracy : 0.324\n",
            "validation loss : 1.716\t validation accuracy : 0.363\n",
            "validation accuracy improved 0.36070 ======> 0.36290\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_7(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (drop): Dropout2d(p=0.25, inplace=False)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.984\t training accuracy : 0.256\n",
            "validation loss : 1.844\t validation accuracy : 0.320\n",
            "validation accuracy improved 0.00000 ======> 0.32020\n",
            "[2/5]\n",
            "training loss : 1.890\t training accuracy : 0.298\n",
            "validation loss : 1.863\t validation accuracy : 0.319\n",
            "[3/5]\n",
            "training loss : 1.870\t training accuracy : 0.304\n",
            "validation loss : 1.792\t validation accuracy : 0.336\n",
            "validation accuracy improved 0.32020 ======> 0.33620\n",
            "[4/5]\n",
            "training loss : 1.849\t training accuracy : 0.319\n",
            "validation loss : 1.796\t validation accuracy : 0.332\n",
            "[5/5]\n",
            "training loss : 1.834\t training accuracy : 0.319\n",
            "validation loss : 1.736\t validation accuracy : 0.354\n",
            "validation accuracy improved 0.33620 ======> 0.35440\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_7(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (drop): Dropout2d(p=0.25, inplace=False)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.023\t training accuracy : 0.240\n",
            "validation loss : 1.928\t validation accuracy : 0.285\n",
            "validation accuracy improved 0.00000 ======> 0.28530\n",
            "[2/5]\n",
            "training loss : 1.934\t training accuracy : 0.286\n",
            "validation loss : 1.896\t validation accuracy : 0.321\n",
            "validation accuracy improved 0.28530 ======> 0.32070\n",
            "[3/5]\n",
            "training loss : 1.890\t training accuracy : 0.307\n",
            "validation loss : 1.805\t validation accuracy : 0.345\n",
            "validation accuracy improved 0.32070 ======> 0.34530\n",
            "[4/5]\n",
            "training loss : 1.872\t training accuracy : 0.315\n",
            "validation loss : 1.758\t validation accuracy : 0.358\n",
            "validation accuracy improved 0.34530 ======> 0.35780\n",
            "[5/5]\n",
            "training loss : 1.856\t training accuracy : 0.323\n",
            "validation loss : 1.755\t validation accuracy : 0.379\n",
            "validation accuracy improved 0.35780 ======> 0.37890\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-6 Change the optimization method"
      ],
      "metadata": {
        "id": "1oF9_bnoxDg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adagrad"
      ],
      "metadata": {
        "id": "Ha2JG8eoxmm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    model = CNN()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adagrad(model.parameters(), lr = learning_rate)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsb8O7LhxPAg",
        "outputId": "b7a70133-149b-4699-ff9b-beb509113d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.598\t training accuracy : 0.414\n",
            "validation loss : 1.411\t validation accuracy : 0.491\n",
            "validation accuracy improved 0.00000 ======> 0.49150\n",
            "[2/5]\n",
            "training loss : 1.355\t training accuracy : 0.507\n",
            "validation loss : 1.330\t validation accuracy : 0.522\n",
            "validation accuracy improved 0.49150 ======> 0.52160\n",
            "[3/5]\n",
            "training loss : 1.275\t training accuracy : 0.540\n",
            "validation loss : 1.279\t validation accuracy : 0.543\n",
            "validation accuracy improved 0.52160 ======> 0.54260\n",
            "[4/5]\n",
            "training loss : 1.226\t training accuracy : 0.559\n",
            "validation loss : 1.237\t validation accuracy : 0.561\n",
            "validation accuracy improved 0.54260 ======> 0.56130\n",
            "[5/5]\n",
            "training loss : 1.189\t training accuracy : 0.575\n",
            "validation loss : 1.213\t validation accuracy : 0.574\n",
            "validation accuracy improved 0.56130 ======> 0.57400\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.533\t training accuracy : 0.440\n",
            "validation loss : 1.356\t validation accuracy : 0.505\n",
            "validation accuracy improved 0.00000 ======> 0.50540\n",
            "[2/5]\n",
            "training loss : 1.298\t training accuracy : 0.530\n",
            "validation loss : 1.270\t validation accuracy : 0.551\n",
            "validation accuracy improved 0.50540 ======> 0.55080\n",
            "[3/5]\n",
            "training loss : 1.219\t training accuracy : 0.562\n",
            "validation loss : 1.217\t validation accuracy : 0.565\n",
            "validation accuracy improved 0.55080 ======> 0.56480\n",
            "[4/5]\n",
            "training loss : 1.166\t training accuracy : 0.582\n",
            "validation loss : 1.175\t validation accuracy : 0.586\n",
            "validation accuracy improved 0.56480 ======> 0.58590\n",
            "[5/5]\n",
            "training loss : 1.127\t training accuracy : 0.598\n",
            "validation loss : 1.154\t validation accuracy : 0.593\n",
            "validation accuracy improved 0.58590 ======> 0.59330\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.586\t training accuracy : 0.422\n",
            "validation loss : 1.437\t validation accuracy : 0.475\n",
            "validation accuracy improved 0.00000 ======> 0.47540\n",
            "[2/5]\n",
            "training loss : 1.376\t training accuracy : 0.502\n",
            "validation loss : 1.372\t validation accuracy : 0.507\n",
            "validation accuracy improved 0.47540 ======> 0.50670\n",
            "[3/5]\n",
            "training loss : 1.305\t training accuracy : 0.533\n",
            "validation loss : 1.316\t validation accuracy : 0.534\n",
            "validation accuracy improved 0.50670 ======> 0.53370\n",
            "[4/5]\n",
            "training loss : 1.257\t training accuracy : 0.551\n",
            "validation loss : 1.277\t validation accuracy : 0.547\n",
            "validation accuracy improved 0.53370 ======> 0.54700\n",
            "[5/5]\n",
            "training loss : 1.220\t training accuracy : 0.565\n",
            "validation loss : 1.244\t validation accuracy : 0.557\n",
            "validation accuracy improved 0.54700 ======> 0.55750\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSProp"
      ],
      "metadata": {
        "id": "wmkwGJno3uJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    model = CNN()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9jd31AQoKQo",
        "outputId": "1c5e1b16-1f35-4cbc-9177-14bbfa7b4ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.103\t training accuracy : 0.341\n",
            "validation loss : 1.538\t validation accuracy : 0.453\n",
            "validation accuracy improved 0.00000 ======> 0.45310\n",
            "[2/5]\n",
            "training loss : 1.511\t training accuracy : 0.460\n",
            "validation loss : 1.484\t validation accuracy : 0.475\n",
            "validation accuracy improved 0.45310 ======> 0.47480\n",
            "[3/5]\n",
            "training loss : 1.431\t training accuracy : 0.495\n",
            "validation loss : 1.491\t validation accuracy : 0.487\n",
            "validation accuracy improved 0.47480 ======> 0.48690\n",
            "[4/5]\n",
            "training loss : 1.377\t training accuracy : 0.518\n",
            "validation loss : 1.437\t validation accuracy : 0.501\n",
            "validation accuracy improved 0.48690 ======> 0.50090\n",
            "[5/5]\n",
            "training loss : 1.336\t training accuracy : 0.538\n",
            "validation loss : 1.420\t validation accuracy : 0.519\n",
            "validation accuracy improved 0.50090 ======> 0.51920\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.045\t training accuracy : 0.364\n",
            "validation loss : 1.533\t validation accuracy : 0.451\n",
            "validation accuracy improved 0.00000 ======> 0.45110\n",
            "[2/5]\n",
            "training loss : 1.504\t training accuracy : 0.458\n",
            "validation loss : 1.506\t validation accuracy : 0.474\n",
            "validation accuracy improved 0.45110 ======> 0.47430\n",
            "[3/5]\n",
            "training loss : 1.412\t training accuracy : 0.500\n",
            "validation loss : 1.495\t validation accuracy : 0.491\n",
            "validation accuracy improved 0.47430 ======> 0.49080\n",
            "[4/5]\n",
            "training loss : 1.358\t training accuracy : 0.523\n",
            "validation loss : 1.419\t validation accuracy : 0.500\n",
            "validation accuracy improved 0.49080 ======> 0.50050\n",
            "[5/5]\n",
            "training loss : 1.317\t training accuracy : 0.540\n",
            "validation loss : 1.402\t validation accuracy : 0.529\n",
            "validation accuracy improved 0.50050 ======> 0.52910\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.076\t training accuracy : 0.287\n",
            "validation loss : 1.693\t validation accuracy : 0.387\n",
            "validation accuracy improved 0.00000 ======> 0.38650\n",
            "[2/5]\n",
            "training loss : 1.684\t training accuracy : 0.389\n",
            "validation loss : 1.609\t validation accuracy : 0.422\n",
            "validation accuracy improved 0.38650 ======> 0.42210\n",
            "[3/5]\n",
            "training loss : 1.552\t training accuracy : 0.438\n",
            "validation loss : 1.505\t validation accuracy : 0.467\n",
            "validation accuracy improved 0.42210 ======> 0.46650\n",
            "[4/5]\n",
            "training loss : 1.491\t training accuracy : 0.465\n",
            "validation loss : 1.619\t validation accuracy : 0.435\n",
            "[5/5]\n",
            "training loss : 1.438\t training accuracy : 0.490\n",
            "validation loss : 1.420\t validation accuracy : 0.502\n",
            "validation accuracy improved 0.46650 ======> 0.50160\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adadelta"
      ],
      "metadata": {
        "id": "H454YF6KF5xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    model = CNN()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adadelta(model.parameters(), lr = learning_rate)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7iwydH1oRH0",
        "outputId": "42e6187b-b4f5-4b6f-e5df-7383fc6a7f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.298\t training accuracy : 0.162\n",
            "validation loss : 2.286\t validation accuracy : 0.187\n",
            "validation accuracy improved 0.00000 ======> 0.18670\n",
            "[2/5]\n",
            "training loss : 2.203\t training accuracy : 0.218\n",
            "validation loss : 2.086\t validation accuracy : 0.252\n",
            "validation accuracy improved 0.18670 ======> 0.25210\n",
            "[3/5]\n",
            "training loss : 2.012\t training accuracy : 0.279\n",
            "validation loss : 1.945\t validation accuracy : 0.317\n",
            "validation accuracy improved 0.25210 ======> 0.31650\n",
            "[4/5]\n",
            "training loss : 1.889\t training accuracy : 0.327\n",
            "validation loss : 1.844\t validation accuracy : 0.344\n",
            "validation accuracy improved 0.31650 ======> 0.34360\n",
            "[5/5]\n",
            "training loss : 1.815\t training accuracy : 0.353\n",
            "validation loss : 1.788\t validation accuracy : 0.359\n",
            "validation accuracy improved 0.34360 ======> 0.35920\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.280\t training accuracy : 0.156\n",
            "validation loss : 2.210\t validation accuracy : 0.192\n",
            "validation accuracy improved 0.00000 ======> 0.19170\n",
            "[2/5]\n",
            "training loss : 2.083\t training accuracy : 0.262\n",
            "validation loss : 1.996\t validation accuracy : 0.297\n",
            "validation accuracy improved 0.19170 ======> 0.29750\n",
            "[3/5]\n",
            "training loss : 1.944\t training accuracy : 0.310\n",
            "validation loss : 1.898\t validation accuracy : 0.328\n",
            "validation accuracy improved 0.29750 ======> 0.32750\n",
            "[4/5]\n",
            "training loss : 1.865\t training accuracy : 0.336\n",
            "validation loss : 1.840\t validation accuracy : 0.350\n",
            "validation accuracy improved 0.32750 ======> 0.34960\n",
            "[5/5]\n",
            "training loss : 1.810\t training accuracy : 0.356\n",
            "validation loss : 1.787\t validation accuracy : 0.366\n",
            "validation accuracy improved 0.34960 ======> 0.36640\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.271\t training accuracy : 0.123\n",
            "validation loss : 2.189\t validation accuracy : 0.210\n",
            "validation accuracy improved 0.00000 ======> 0.21020\n",
            "[2/5]\n",
            "training loss : 2.078\t training accuracy : 0.257\n",
            "validation loss : 1.987\t validation accuracy : 0.308\n",
            "validation accuracy improved 0.21020 ======> 0.30760\n",
            "[3/5]\n",
            "training loss : 1.918\t training accuracy : 0.319\n",
            "validation loss : 1.865\t validation accuracy : 0.338\n",
            "validation accuracy improved 0.30760 ======> 0.33810\n",
            "[4/5]\n",
            "training loss : 1.824\t training accuracy : 0.348\n",
            "validation loss : 1.789\t validation accuracy : 0.368\n",
            "validation accuracy improved 0.33810 ======> 0.36800\n",
            "[5/5]\n",
            "training loss : 1.757\t training accuracy : 0.371\n",
            "validation loss : 1.727\t validation accuracy : 0.390\n",
            "validation accuracy improved 0.36800 ======> 0.38960\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2-7 Xavier weight initialization"
      ],
      "metadata": {
        "id": "Eli5MFOlIWdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_8(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_8, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding='same')\n",
        "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding= 'same')\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 8 * 8 * 16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "--fP7OPpokhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    model = CNN_8()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH1hLjYoo26q",
        "outputId": "561b02bb-1c19-4c5f-94ca-83325bb1ad4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_8(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.646\t training accuracy : 0.400\n",
            "validation loss : 1.547\t validation accuracy : 0.447\n",
            "validation accuracy improved 0.00000 ======> 0.44690\n",
            "[2/5]\n",
            "training loss : 1.471\t training accuracy : 0.471\n",
            "validation loss : 1.441\t validation accuracy : 0.497\n",
            "validation accuracy improved 0.44690 ======> 0.49740\n",
            "[3/5]\n",
            "training loss : 1.398\t training accuracy : 0.503\n",
            "validation loss : 1.430\t validation accuracy : 0.509\n",
            "validation accuracy improved 0.49740 ======> 0.50860\n",
            "[4/5]\n",
            "training loss : 1.351\t training accuracy : 0.522\n",
            "validation loss : 1.459\t validation accuracy : 0.491\n",
            "[5/5]\n",
            "training loss : 1.311\t training accuracy : 0.539\n",
            "validation loss : 1.409\t validation accuracy : 0.510\n",
            "validation accuracy improved 0.50860 ======> 0.51020\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_8(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.688\t training accuracy : 0.378\n",
            "validation loss : 1.534\t validation accuracy : 0.449\n",
            "validation accuracy improved 0.00000 ======> 0.44930\n",
            "[2/5]\n",
            "training loss : 1.527\t training accuracy : 0.451\n",
            "validation loss : 1.488\t validation accuracy : 0.468\n",
            "validation accuracy improved 0.44930 ======> 0.46770\n",
            "[3/5]\n",
            "training loss : 1.459\t training accuracy : 0.475\n",
            "validation loss : 1.478\t validation accuracy : 0.475\n",
            "validation accuracy improved 0.46770 ======> 0.47530\n",
            "[4/5]\n",
            "training loss : 1.408\t training accuracy : 0.500\n",
            "validation loss : 1.509\t validation accuracy : 0.464\n",
            "[5/5]\n",
            "training loss : 1.374\t training accuracy : 0.513\n",
            "validation loss : 1.450\t validation accuracy : 0.493\n",
            "validation accuracy improved 0.47530 ======> 0.49330\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN_8(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.692\t training accuracy : 0.379\n",
            "validation loss : 1.620\t validation accuracy : 0.423\n",
            "validation accuracy improved 0.00000 ======> 0.42350\n",
            "[2/5]\n",
            "training loss : 1.531\t training accuracy : 0.447\n",
            "validation loss : 1.573\t validation accuracy : 0.430\n",
            "validation accuracy improved 0.42350 ======> 0.42960\n",
            "[3/5]\n",
            "training loss : 1.476\t training accuracy : 0.472\n",
            "validation loss : 1.465\t validation accuracy : 0.476\n",
            "validation accuracy improved 0.42960 ======> 0.47590\n",
            "[4/5]\n",
            "training loss : 1.442\t training accuracy : 0.484\n",
            "validation loss : 1.403\t validation accuracy : 0.506\n",
            "validation accuracy improved 0.47590 ======> 0.50560\n",
            "[5/5]\n",
            "training loss : 1.412\t training accuracy : 0.500\n",
            "validation loss : 1.416\t validation accuracy : 0.505\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2-8 Change learning rate"
      ],
      "metadata": {
        "id": "Ak-xSX-KdGzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate2 = 0.02\n",
        "\n",
        "for i in range(0,3):\n",
        "    model = CNN()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate2)\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGtKqZRHdSB1",
        "outputId": "3b0c2f22-9bf5-4ee4-c749-392968043bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.994\t training accuracy : 0.253\n",
            "validation loss : 1.904\t validation accuracy : 0.301\n",
            "validation accuracy improved 0.00000 ======> 0.30120\n",
            "[2/5]\n",
            "training loss : 1.917\t training accuracy : 0.290\n",
            "validation loss : 1.877\t validation accuracy : 0.308\n",
            "validation accuracy improved 0.30120 ======> 0.30810\n",
            "[3/5]\n",
            "training loss : 1.891\t training accuracy : 0.297\n",
            "validation loss : 1.887\t validation accuracy : 0.312\n",
            "validation accuracy improved 0.30810 ======> 0.31230\n",
            "[4/5]\n",
            "training loss : 1.888\t training accuracy : 0.301\n",
            "validation loss : 1.849\t validation accuracy : 0.335\n",
            "validation accuracy improved 0.31230 ======> 0.33480\n",
            "[5/5]\n",
            "training loss : 1.879\t training accuracy : 0.304\n",
            "validation loss : 1.853\t validation accuracy : 0.312\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.080\t training accuracy : 0.217\n",
            "validation loss : 1.995\t validation accuracy : 0.253\n",
            "validation accuracy improved 0.00000 ======> 0.25260\n",
            "[2/5]\n",
            "training loss : 1.959\t training accuracy : 0.271\n",
            "validation loss : 1.919\t validation accuracy : 0.283\n",
            "validation accuracy improved 0.25260 ======> 0.28340\n",
            "[3/5]\n",
            "training loss : 1.942\t training accuracy : 0.278\n",
            "validation loss : 1.955\t validation accuracy : 0.281\n",
            "[4/5]\n",
            "training loss : 1.927\t training accuracy : 0.288\n",
            "validation loss : 1.904\t validation accuracy : 0.303\n",
            "validation accuracy improved 0.28340 ======> 0.30290\n",
            "[5/5]\n",
            "training loss : 1.921\t training accuracy : 0.290\n",
            "validation loss : 1.921\t validation accuracy : 0.295\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 2.307\t training accuracy : 0.103\n",
            "validation loss : 2.305\t validation accuracy : 0.102\n",
            "validation accuracy improved 0.00000 ======> 0.10220\n",
            "[2/5]\n",
            "training loss : 2.305\t training accuracy : 0.101\n",
            "validation loss : 2.306\t validation accuracy : 0.101\n",
            "[3/5]\n",
            "training loss : 2.305\t training accuracy : 0.103\n",
            "validation loss : 2.303\t validation accuracy : 0.100\n",
            "[4/5]\n",
            "training loss : 2.305\t training accuracy : 0.099\n",
            "validation loss : 2.305\t validation accuracy : 0.097\n",
            "[5/5]\n",
            "training loss : 2.305\t training accuracy : 0.100\n",
            "validation loss : 2.306\t validation accuracy : 0.100\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2-8-1 plot"
      ],
      "metadata": {
        "id": "SgbNp6-3d7Aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "np_loss = np.array(valid_loss)\n",
        "loss_ind_sorted = np.argsort(np_loss)\n",
        "loss_min_ind = loss_ind_sorted[0]\n",
        "\n",
        "x = [i+1 for i in range(len(train_loss))]\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Loss curve')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(x, train_loss, label='train_loss')\n",
        "plt.plot(x, valid_loss, label='valid_loss')\n",
        "plt.axvline(loss_min_ind+1, color='red')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "sIMV5ARZd5fA",
        "outputId": "04eb7abb-a3b7-4059-8b55-5bdb568a2b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f294d8f6190>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2-9 L2 (ridge) regularization method"
      ],
      "metadata": {
        "id": "QeYlbsd0fwht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.patches import RegularPolygon\n",
        "for i in range(0,3):\n",
        "    model = CNN()\n",
        "    print(model)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 1e-5)\n",
        "    n_epochs = 5\n",
        "    train_loss = [] # train loss per epoch\n",
        "    valid_loss = [] # valid loss per epoch\n",
        "    \n",
        "    train_acc = [] # train accuracy per epoch\n",
        "    valid_acc = [] # valid accuracy per epoch\n",
        "    \n",
        "    # update following two variables whenever valid accuracy improves\n",
        "    best_model = copy.deepcopy(model)\n",
        "    best_acc = 0\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # set model as training mode(for compute gradient)\n",
        "        train_total = 0\n",
        "        train_correct = 0\n",
        "        epoch_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            inputs, labels = data[0], data[1]\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            epoch_train_loss += loss.item()\n",
        "            loss.backward() # compute gradient\n",
        "            optimizer.step() # update weight & bias in the model with computed gradient\n",
        "            \n",
        "        train_loss.append(epoch_train_loss/len(train_loader))\n",
        "        train_acc.append(train_correct/train_total)\n",
        "        \n",
        "        model.eval() # set model as evaluation mode\n",
        "        with torch.no_grad():# we don't need to compute gradient during the evaluation process\n",
        "            valid_total = 0\n",
        "            valid_correct = 0\n",
        "            epoch_valid_loss = 0\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data[0], data[1]\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                valid_total += labels.size(0)\n",
        "                valid_correct += (predicted == labels).sum().item()\n",
        "                \n",
        "                loss = loss_function(outputs, labels)\n",
        "                epoch_valid_loss += loss.item()\n",
        "            \n",
        "            valid_loss.append(epoch_valid_loss/len(valid_loader))\n",
        "            valid_acc.append(valid_correct / valid_total)\n",
        "            \n",
        "        print('[{}/{}]'.format(epoch+1, n_epochs))\n",
        "        print('training loss : {:.3f}\\t training accuracy : {:.3f}'.format(epoch_train_loss/len(train_loader), train_correct/train_total))\n",
        "        print('validation loss : {:.3f}\\t validation accuracy : {:.3f}'.format(epoch_valid_loss/len(valid_loader), valid_correct/valid_total))\n",
        "        \n",
        "        if valid_correct/valid_total > best_acc:\n",
        "            print('validation accuracy improved {:.5f} ======> {:.5f}'.format(best_acc, valid_correct/valid_total))\n",
        "            best_acc = valid_correct/valid_total\n",
        "            best_model = copy.deepcopy(model)\n",
        "    print(\"-----------------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btrg_uKTf-PV",
        "outputId": "ade7bbeb-f2d8-4432-b955-787088f64192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.830\t training accuracy : 0.309\n",
            "validation loss : 1.708\t validation accuracy : 0.355\n",
            "validation accuracy improved 0.00000 ======> 0.35470\n",
            "[2/5]\n",
            "training loss : 1.676\t training accuracy : 0.367\n",
            "validation loss : 1.688\t validation accuracy : 0.367\n",
            "validation accuracy improved 0.35470 ======> 0.36720\n",
            "[3/5]\n",
            "training loss : 1.635\t training accuracy : 0.385\n",
            "validation loss : 1.689\t validation accuracy : 0.376\n",
            "validation accuracy improved 0.36720 ======> 0.37560\n",
            "[4/5]\n",
            "training loss : 1.592\t training accuracy : 0.408\n",
            "validation loss : 1.636\t validation accuracy : 0.395\n",
            "validation accuracy improved 0.37560 ======> 0.39530\n",
            "[5/5]\n",
            "training loss : 1.570\t training accuracy : 0.423\n",
            "validation loss : 1.626\t validation accuracy : 0.407\n",
            "validation accuracy improved 0.39530 ======> 0.40680\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.828\t training accuracy : 0.319\n",
            "validation loss : 1.693\t validation accuracy : 0.378\n",
            "validation accuracy improved 0.00000 ======> 0.37790\n",
            "[2/5]\n",
            "training loss : 1.657\t training accuracy : 0.396\n",
            "validation loss : 1.595\t validation accuracy : 0.412\n",
            "validation accuracy improved 0.37790 ======> 0.41160\n",
            "[3/5]\n",
            "training loss : 1.571\t training accuracy : 0.426\n",
            "validation loss : 1.569\t validation accuracy : 0.434\n",
            "validation accuracy improved 0.41160 ======> 0.43410\n",
            "[4/5]\n",
            "training loss : 1.519\t training accuracy : 0.449\n",
            "validation loss : 1.540\t validation accuracy : 0.439\n",
            "validation accuracy improved 0.43410 ======> 0.43910\n",
            "[5/5]\n",
            "training loss : 1.491\t training accuracy : 0.457\n",
            "validation loss : 1.529\t validation accuracy : 0.446\n",
            "validation accuracy improved 0.43910 ======> 0.44600\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "[1/5]\n",
            "training loss : 1.663\t training accuracy : 0.389\n",
            "validation loss : 1.572\t validation accuracy : 0.435\n",
            "validation accuracy improved 0.00000 ======> 0.43520\n",
            "[2/5]\n",
            "training loss : 1.491\t training accuracy : 0.464\n",
            "validation loss : 1.580\t validation accuracy : 0.434\n",
            "[3/5]\n",
            "training loss : 1.407\t training accuracy : 0.500\n",
            "validation loss : 1.460\t validation accuracy : 0.489\n",
            "validation accuracy improved 0.43520 ======> 0.48900\n",
            "[4/5]\n",
            "training loss : 1.361\t training accuracy : 0.516\n",
            "validation loss : 1.419\t validation accuracy : 0.507\n",
            "validation accuracy improved 0.48900 ======> 0.50730\n",
            "[5/5]\n",
            "training loss : 1.324\t training accuracy : 0.532\n",
            "validation loss : 1.501\t validation accuracy : 0.488\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}